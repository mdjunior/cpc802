{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CPC802-1-logreg-word.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ioWWZrFNHYI",
        "colab_type": "text"
      },
      "source": [
        "# CPC802: Tópicos Especiais em Inteligência Computacional\n",
        "\n",
        "A proposta do seguinte código é analisar um conjunto de eventos do protocolo HTTP. Essa análise tem por objetivo treinar um classificador para otimizar o tempo de um analisador de protocolo completo, ou seja, treinaremos o classificador para determinar quando um evento deve ser analisado de forma completa ou não.\n",
        "\n",
        "Cabe lembrar que existem pesos diferentes:\n",
        "- falso-positivo (não é um evento malicioso mas foi marcado para envio ao analisador de protocolo): só estamos desperdiçando tempo do analisador (isso não é um problema).\n",
        "- falso-negativo (é um evento malicioso mas foi marcado para não enviar ao analisador de protocolo): devemos evitar esse comportamento pois nesse caso deixaremos um evento malicioso sem ser analisado.\n",
        "\n",
        "O presente código analisa as URLs separando elas em **tokens**. Mais detalhes estão na função `getTokens`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhe7KjuaHpJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carregamos as bibliotecas.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viYziSPNIB6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkgz1ipxIF8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib.parse\n",
        "\n",
        "# Função que lê os dados do arquivo.\n",
        "def loadFile(name):\n",
        "    # Obtém diretório e nome completo do arquivo (com path).\n",
        "    directory = str(os.getcwd())\n",
        "    filepath = os.path.join(directory, name)\n",
        "\n",
        "    # Faz a leitura das linhas do arquivo.\n",
        "    with open(filepath,'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    # Transforma as linhas em um Set (retira as duplicadas) e depois em uma lista.\n",
        "    data = list(set(data))\n",
        "\n",
        "    # Realiza o decode das URLs e coloca elas na lista result.\n",
        "    result = []\n",
        "    for d in data:\n",
        "        d = str(urllib.parse.unquote(d))\n",
        "        result.append(d)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRIZr0Zf4YhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "# Função que separa cada URL em uma lista de palavras/tokens, utilizando como separadores: '/', '-', '.'\n",
        "def getTokens(input):\n",
        "    return re.split('/|-|\\.|=|&|\\?|\\s+|\\<|\\>|;|\\(|\\)', str(input.encode('utf-8')))\n",
        "\n",
        "# Exemplo:\n",
        "# getTokens('/wikipedia/noticias/museu-nacional-e-10.php?paramenter=10&c=select * from table&opa=<xss(alert)>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zca_MRlOM_mL",
        "colab_type": "text"
      },
      "source": [
        "Vamos fazer a leitura dos dados do Google Drive (estamos executando no Google Colab para validação)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkVTQuSqIIuT",
        "colab_type": "code",
        "outputId": "0d7b6f23-526c-4d20-9939-632318fc87ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH8iRtEAIyEH",
        "colab_type": "code",
        "outputId": "c4b660bf-c54a-4dd2-d3e7-622865ef2a6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd drive/'My Drive'/'Colab Notebooks'/cpc802"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/Colab Notebooks/cpc802'\n",
            "/content/drive/My Drive/Colab Notebooks/cpc802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPmTkgPYKKVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criamos uma instância de dicionário para converter as URLs em representações\n",
        "#   numéricas de acordo com a frequência de utilização deles.\n",
        "#vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3))\n",
        "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"word\", sublinear_tf=True, tokenizer=getTokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SECyzjx_RaYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carrega os dados dos arquivos\n",
        "badQueries = loadFile('badqueries_gg.txt')\n",
        "validQueries = loadFile('goodqueries_gg.txt')\n",
        "\n",
        "allQueries = badQueries + validQueries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zen-bT8QI9hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Geramos o vetor de conversão para as URLs.\n",
        "X = vectorizer.fit_transform(allQueries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcqGSyZiSyyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vamos colocar os labels\n",
        "#   0 - normal\n",
        "#   1 - malicious\n",
        "yBad = [1 for i in range(0, len(badQueries))]\n",
        "yGood = [0 for i in range(0, len(validQueries))]\n",
        "\n",
        "y = yBad + yGood\n",
        "\n",
        "# Vamos gerar os dados de treinamento e validação\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOYOiS_4KOLr",
        "colab_type": "code",
        "outputId": "68d420f0-2a07-4389-ed3a-61e7dc002967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "badCount = len(badQueries)\n",
        "badCount"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21517"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeVHojw0TF7b",
        "colab_type": "code",
        "outputId": "fd58920d-cf09-4f65-acad-4bfcf05bf15d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validCount = len(validQueries)\n",
        "validCount"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33281"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZq2eEmhKcda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criamos um classificador usando regressão logística.\n",
        "lgs = LogisticRegression(class_weight='balanced', max_iter=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRhs2HHnKspF",
        "colab_type": "code",
        "outputId": "86469fb9-0dde-45b5-835e-7273e6373b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Treinando o modelo.\n",
        "lgs.fit(X_train, y_train)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=400, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUdkpQ_cDaEr",
        "colab_type": "code",
        "outputId": "f1df9d6e-870e-4a8b-f9d7-d5c050d77a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Salva modelo treinado no Google Drive.\n",
        "import joblib\n",
        "import time\n",
        "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "filename = 'cpc802-' + timestr + '-word.sav'\n",
        "joblib.dump(lgs, filename)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cpc802-20200229-223546-word.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV2zv2yDKd5K",
        "colab_type": "code",
        "outputId": "ec9e7a13-25f3-4706-f1cc-53e191763da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Validamos o modelo\n",
        "predicted = lgs.predict(X_test)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, (lgs.predict_proba(X_test)[:, 1]))\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "print(\"Bad samples: %d\" % badCount)\n",
        "print(\"Good samples: %d\" % validCount)\n",
        "print(\"Baseline Constant negative: %.6f\" % (validCount / (validCount + badCount)))\n",
        "print(\"Accuracy: %f\" % lgs.score(X_test, y_test))\n",
        "print(\"Precision: %f\" % metrics.precision_score(y_test, predicted))\n",
        "print(\"Recall: %f\" % metrics.recall_score(y_test, predicted))\n",
        "print(\"F1-Score: %f\" % metrics.f1_score(y_test, predicted))\n",
        "print(\"AUC: %f\" % auc)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bad samples: 21517\n",
            "Good samples: 33281\n",
            "Baseline Constant negative: 0.607340\n",
            "Accuracy: 0.962591\n",
            "Precision: 0.977827\n",
            "Recall: 0.925391\n",
            "F1-Score: 0.950886\n",
            "AUC: 0.957699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UEe_ApDWOft",
        "colab_type": "code",
        "outputId": "548ab4ad-98cc-4915-e971-054374290a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Testando com valores conhecidos.\n",
        "X_predict = [\n",
        "             '/busca/manoel',\n",
        "             '/search=faizanahad',\n",
        "             '/getpassword.php',\n",
        "             '/wp-admin/includes/log.exe',\n",
        "             '/nethost.exe',\n",
        "             '/centroesteticosothys/img/_notes/gum.exe?c=select * from table',\n",
        "             '/node/add',\n",
        "             ]\n",
        "X_predict = vectorizer.transform(X_predict)\n",
        "y_Predict = lgs.predict_log_proba(X_predict)\n",
        "print(y_Predict)\n",
        "y_Predict = lgs.predict(X_predict)\n",
        "print(y_Predict)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-9.46840579e-05 -9.26501226e+00]\n",
            " [-2.91584066e-01 -1.37467891e+00]\n",
            " [-3.38573178e-03 -5.68987760e+00]\n",
            " [-3.23149301e+00 -4.02997174e-02]\n",
            " [-3.38573178e-03 -5.68987760e+00]\n",
            " [-1.11752934e+00 -3.96139109e-01]\n",
            " [-1.80582871e-01 -1.80049853e+00]]\n",
            "[0 0 0 1 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMAtm9DnVkxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepara dataset real apenas para validação.\n",
        "otherBadQueries = loadFile('badqueries.txt')\n",
        "otherGoodQueries = loadFile('goodqueries.txt')\n",
        "allOtherQueries = otherBadQueries + otherGoodQueries\n",
        "\n",
        "# Vetoriza dataset real.\n",
        "X_real = vectorizer.transform(allOtherQueries)\n",
        "\n",
        "# Calcula as inferências do dataset real.\n",
        "y_real = lgs.predict(X_real)\n",
        "\n",
        "# Vamos colocar os labels no dataset real.\n",
        "#   0 - normal\n",
        "#   1 - malicious\n",
        "yBad_gg = [1 for i in range(0, len(otherBadQueries))]\n",
        "yGood_gg = [0 for i in range(0, len(otherGoodQueries))]\n",
        "y_real_with_label = yBad_gg + yGood_gg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieX3JkRFYThu",
        "colab_type": "code",
        "outputId": "2393a882-0a71-44c1-db67-05aaa4dd3820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Verifica acertos e erros de predição usando dataset real.\n",
        "acertos = 0\n",
        "erros = 0\n",
        "for i in range(len(y_real)):\n",
        "    if y_real[i] == y_real_with_label[i]:\n",
        "        acertos = acertos + 1\n",
        "    elif (y_real_with_label[i] == 0 and y_real[i] == 1):\n",
        "        acertos = acertos + 1\n",
        "    else:\n",
        "        erros = erros + 1\n",
        "\n",
        "acertos/len(y_real)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9945640024811037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY4Q74d-bT2x",
        "colab_type": "code",
        "outputId": "3f325b46-d57d-4d65-a028-185264bb612a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Verifica acertos e erros de predição usando dataset de treino (é para verificar a acurácia).\n",
        "#   Nessa verificação levamos em conta os erros que não prejudicam a avaliação do domínio\n",
        "#   do problema, ou seja, quando o classificador aponta que uma URL é maliciosa e ela\n",
        "#   não é.\n",
        "\n",
        "# Vetoriza dataset usado no treinamento.\n",
        "X_trained = vectorizer.transform(allQueries)\n",
        "\n",
        "# Calcula as inferências do dataset real.\n",
        "y_trained = lgs.predict(X_trained)\n",
        "\n",
        "acertos = 0\n",
        "erros = 0\n",
        "for i in range(len(y_trained)):\n",
        "    if y_trained[i] == y[i]:\n",
        "        acertos = acertos + 1\n",
        "    elif (y[i] == 0 and y_trained[i] == 1):\n",
        "        acertos = acertos + 1\n",
        "    else:\n",
        "        erros = erros + 1\n",
        "\n",
        "acertos/len(y_trained)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9728457242965072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    }
  ]
}