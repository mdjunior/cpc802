{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CPC802-1-logreg-word.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ioWWZrFNHYI",
        "colab_type": "text"
      },
      "source": [
        "# CPC802: Tópicos Especiais em Inteligência Computacional\n",
        "\n",
        "A proposta do seguinte código é analisar um conjunto de eventos do protocolo HTTP. Essa análise tem por objetivo treinar um classificador para otimizar o tempo de um analisador de protocolo completo, ou seja, treinaremos o classificador para determinar quando um evento deve ser analisado de forma completa ou não.\n",
        "\n",
        "Cabe lembrar que existem pesos diferentes:\n",
        "- falso-positivo (não é um evento malicioso mas foi marcado para envio ao analisador de protocolo): só estamos desperdiçando tempo do analisador (isso não é um problema).\n",
        "- falso-negativo (é um evento malicioso mas foi marcado para não enviar ao analisador de protocolo): devemos evitar esse comportamento pois nesse caso deixaremos um evento malicioso sem ser analisado.\n",
        "\n",
        "O presente código analisa as URLs separando elas em **tokens** ou **caracteres**. Mais detalhes estão na função `getTokens`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ldY82YTFaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# Configurações do código\n",
        "################################################################################\n",
        "\n",
        "# Utilização de tokens/words ou de caracteres. Caso seja True, usa words, caso seja False, utiliza caracteres.\n",
        "use_words = True\n",
        "\n",
        "# Expressão regular utilizada como separador das URLs.\n",
        "tokensSep = '/|-|\\.|=|&|\\?|\\s+|\\<|\\>|;|\\(|\\)'\n",
        "\n",
        "# Utilização dos arquivos:\n",
        "fileForTrainingBad = 'badqueries.txt'\n",
        "fileForTrainingGood = 'goodqueries.txt'\n",
        "\n",
        "fileForValidationBad = 'badqueries_gg.txt'\n",
        "fileForValidationGood = 'goodqueries_gg.txt'\n",
        "\n",
        "# Sufixo para escrita do nome do arquivo\n",
        "saveSuffix = '-word'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhe7KjuaHpJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carregamos as bibliotecas.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkgz1ipxIF8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib.parse\n",
        "\n",
        "# Função que lê os dados do arquivo.\n",
        "def loadFile(name):\n",
        "    # Obtém diretório e nome completo do arquivo (com path).\n",
        "    directory = str(os.getcwd())\n",
        "    filepath = os.path.join(directory, name)\n",
        "\n",
        "    # Faz a leitura das linhas do arquivo.\n",
        "    with open(filepath,'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    # Transforma as linhas em um Set (retira as duplicadas) e depois em uma lista.\n",
        "    data = list(set(data))\n",
        "\n",
        "    # Realiza o decode das URLs e coloca elas na lista result.\n",
        "    result = []\n",
        "    for d in data:\n",
        "        d = str(urllib.parse.unquote(d))\n",
        "        result.append(d)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRIZr0Zf4YhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "# Função que separa cada URL em uma lista de palavras/tokens, utilizando como separadores: '/', '-', '.'\n",
        "def getTokens(input):\n",
        "    return re.split(tokensSep, str(input.encode('utf-8')))\n",
        "\n",
        "# Exemplo:\n",
        "# getTokens('/wikipedia/noticias/museu-nacional-e-10.php?paramenter=10&c=select * from table&opa=<xss(alert)>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zca_MRlOM_mL",
        "colab_type": "text"
      },
      "source": [
        "Vamos fazer a leitura dos dados do Google Drive (estamos executando no Google Colab para validação)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkVTQuSqIIuT",
        "colab_type": "code",
        "outputId": "10e18c5a-2fa8-4951-bd1c-f52a05b7b900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH8iRtEAIyEH",
        "colab_type": "code",
        "outputId": "4427a0e5-dfdc-4edd-b3e3-5b4fb389b089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd drive/'My Drive'/'Colab Notebooks'/cpc802"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/Colab Notebooks/cpc802'\n",
            "/content/drive/My Drive/Colab Notebooks/cpc802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPmTkgPYKKVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criamos uma instância de dicionário para converter as URLs em representações\n",
        "#   numéricas de acordo com a frequência de utilização deles.\n",
        "if use_words:\n",
        "    vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"word\", sublinear_tf=True, tokenizer=getTokens)\n",
        "else:\n",
        "    vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SECyzjx_RaYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carrega os dados dos arquivos\n",
        "badQueries = loadFile(fileForTrainingBad)\n",
        "validQueries = loadFile(fileForTrainingGood)\n",
        "\n",
        "allQueries = badQueries + validQueries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zen-bT8QI9hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Geramos o vetor de conversão para as URLs.\n",
        "X = vectorizer.fit_transform(allQueries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcqGSyZiSyyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vamos colocar os labels\n",
        "#   0 - normal\n",
        "#   1 - malicious\n",
        "yBad = [1 for i in range(0, len(badQueries))]\n",
        "yGood = [0 for i in range(0, len(validQueries))]\n",
        "\n",
        "y = yBad + yGood\n",
        "\n",
        "# Vamos gerar os dados de treinamento e validação\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOYOiS_4KOLr",
        "colab_type": "code",
        "outputId": "d4546c4a-3ced-4c9a-f3f7-9051ff665b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "badCount = len(badQueries)\n",
        "badCount"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44713"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeVHojw0TF7b",
        "colab_type": "code",
        "outputId": "30f63da7-b796-455b-fd87-1e0c38300f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validCount = len(validQueries)\n",
        "validCount"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1265994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZq2eEmhKcda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criamos um classificador usando regressão logística.\n",
        "lgs = LogisticRegression(class_weight='balanced', max_iter=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRhs2HHnKspF",
        "colab_type": "code",
        "outputId": "7650a372-c04d-4fdd-f31f-13b898b30a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Treinando o modelo.\n",
        "lgs.fit(X_train, y_train)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=400, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUdkpQ_cDaEr",
        "colab_type": "code",
        "outputId": "490a692d-fb43-4750-f446-2f5055e2fcb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Salva modelo treinado no Google Drive.\n",
        "import joblib\n",
        "import time\n",
        "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "filename = 'cpc802-' + timestr + saveSuffix + '.sav'\n",
        "filenameVectorizer = 'cpc802-' + timestr + saveSuffix +'.vectorizer'\n",
        "joblib.dump(lgs, filename)\n",
        "joblib.dump(vectorizer, filenameVectorizer)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cpc802-20200229-234322-word.vectorizer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV2zv2yDKd5K",
        "colab_type": "code",
        "outputId": "4c8e34cb-7c56-459b-d59f-94199b68513b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Validamos o modelo\n",
        "predicted = lgs.predict(X_test)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, (lgs.predict_proba(X_test)[:, 1]))\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "print(\"Bad samples: %d\" % badCount)\n",
        "print(\"Good samples: %d\" % validCount)\n",
        "print(\"Baseline Constant negative: %.6f\" % (validCount / (validCount + badCount)))\n",
        "print(\"Accuracy: %f\" % lgs.score(X_test, y_test))\n",
        "print(\"Precision: %f\" % metrics.precision_score(y_test, predicted))\n",
        "print(\"Recall: %f\" % metrics.recall_score(y_test, predicted))\n",
        "print(\"F1-Score: %f\" % metrics.f1_score(y_test, predicted))\n",
        "print(\"AUC: %f\" % auc)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bad samples: 44713\n",
            "Good samples: 1265994\n",
            "Baseline Constant negative: 0.965886\n",
            "Accuracy: 0.996353\n",
            "Precision: 0.930887\n",
            "Recall: 0.963169\n",
            "F1-Score: 0.946753\n",
            "AUC: 0.990835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UEe_ApDWOft",
        "colab_type": "code",
        "outputId": "2b0bd88f-d7e9-4f43-861f-312e1d3dedcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Testando com valores conhecidos.\n",
        "X_predict = [\n",
        "             '/busca/manoel',\n",
        "             '/search=faizanahad',\n",
        "             '/getpassword.php',\n",
        "             '/wp-admin/includes/log.exe',\n",
        "             '/nethost.exe',\n",
        "             '/centroesteticosothys/img/_notes/gum.exe?c=select * from table',\n",
        "             '/node/add',\n",
        "             ]\n",
        "X_predict = vectorizer.transform(X_predict)\n",
        "y_Predict = lgs.predict_log_proba(X_predict)\n",
        "print(y_Predict)\n",
        "y_Predict = lgs.predict(X_predict)\n",
        "print(y_Predict)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-4.91809773e-02 -3.03673808e+00]\n",
            " [-1.11225812e-01 -2.25129029e+00]\n",
            " [-5.16207267e-02 -2.98953134e+00]\n",
            " [-7.43347875e-02 -2.63611340e+00]\n",
            " [-4.81886957e-02 -3.05662841e+00]\n",
            " [-6.40222893e+00 -1.65923366e-03]\n",
            " [-5.99172427e-02 -2.84460000e+00]]\n",
            "[0 0 0 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMAtm9DnVkxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepara dataset real apenas para validação.\n",
        "otherBadQueries = loadFile(fileForValidationBad)\n",
        "otherGoodQueries = loadFile(fileForValidationGood)\n",
        "allOtherQueries = otherBadQueries + otherGoodQueries\n",
        "\n",
        "# Vetoriza dataset real.\n",
        "X_real = vectorizer.transform(allOtherQueries)\n",
        "\n",
        "# Calcula as inferências do dataset real.\n",
        "y_real = lgs.predict(X_real)\n",
        "\n",
        "# Vamos colocar os labels no dataset real.\n",
        "#   0 - normal\n",
        "#   1 - malicious\n",
        "yBad_gg = [1 for i in range(0, len(otherBadQueries))]\n",
        "yGood_gg = [0 for i in range(0, len(otherGoodQueries))]\n",
        "y_real_with_label = yBad_gg + yGood_gg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieX3JkRFYThu",
        "colab_type": "code",
        "outputId": "d7a7ff63-bea7-4ead-f57c-4df4cf4629cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Verifica acertos e erros de predição usando dataset real.\n",
        "acertos = 0\n",
        "erros = 0\n",
        "for i in range(len(y_real)):\n",
        "    if y_real[i] == y_real_with_label[i]:\n",
        "        acertos = acertos + 1\n",
        "    elif (y_real_with_label[i] == 0 and y_real[i] == 1):\n",
        "        acertos = acertos + 1\n",
        "    else:\n",
        "        erros = erros + 1\n",
        "\n",
        "acertos/len(y_real)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9099784663673857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY4Q74d-bT2x",
        "colab_type": "code",
        "outputId": "43b29bd4-cc03-4ece-f6d7-9eb7d36e1544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Verifica acertos e erros de predição usando dataset de treino (é para verificar a acurácia).\n",
        "#   Nessa verificação levamos em conta os erros que não prejudicam a avaliação do domínio\n",
        "#   do problema, ou seja, quando o classificador aponta que uma URL é maliciosa e ela\n",
        "#   não é.\n",
        "\n",
        "# Vetoriza dataset usado no treinamento.\n",
        "X_trained = vectorizer.transform(allQueries)\n",
        "\n",
        "# Calcula as inferências do dataset real.\n",
        "y_trained = lgs.predict(X_trained)\n",
        "\n",
        "acertos = 0\n",
        "erros = 0\n",
        "for i in range(len(y_trained)):\n",
        "    if y_trained[i] == y[i]:\n",
        "        acertos = acertos + 1\n",
        "    elif (y[i] == 0 and y_trained[i] == 1):\n",
        "        acertos = acertos + 1\n",
        "    else:\n",
        "        erros = erros + 1\n",
        "\n",
        "acertos/len(y_trained)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.999735257383992"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    }
  ]
}