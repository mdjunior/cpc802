{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CPC802-1-logreg-word.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ioWWZrFNHYI",
        "colab_type": "text"
      },
      "source": [
        "# CPC802: Tópicos Especiais em Inteligência Computacional\n",
        "\n",
        "A proposta do seguinte código é analisar um conjunto de eventos do protocolo HTTP. Essa análise tem por objetivo treinar um classificador para otimizar o tempo de um analisador de protocolo completo, ou seja, treinaremos o classificador para determinar quando um evento deve ser analisado de forma completa ou não.\n",
        "\n",
        "Cabe lembrar que existem pesos diferentes:\n",
        "- falso-positivo (não é um evento malicioso mas foi marcado para envio ao analisador de protocolo): só estamos desperdiçando tempo do analisador (isso não é um problema).\n",
        "- falso-negativo (é um evento malicioso mas foi marcado para não enviar ao analisador de protocolo): devemos evitar esse comportamento pois nesse caso deixaremos um evento malicioso sem ser analisado.\n",
        "\n",
        "O presente código analisa as URLs separando elas em **tokens** ou **caracteres**. Mais detalhes estão na função `getTokens`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ldY82YTFaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# Configurações do código\n",
        "################################################################################\n",
        "\n",
        "# Utilização de tokens/words ou de caracteres. Caso seja True, usa words, caso seja False, utiliza caracteres.\n",
        "use_words = True\n",
        "\n",
        "# Método utilizado para treinar modelo. Pode ser:\n",
        "# - 'logreg': Regressão logística\n",
        "# - 'lsvm': Linear Support Vector Classification\n",
        "method = 'lsvm'\n",
        "\n",
        "# Expressão regular utilizada como separador das URLs.\n",
        "tokensSep = '/|-|\\.|=|&|\\?|\\s+|\\<|\\>|;|\\(|\\)'\n",
        "\n",
        "# Utilização dos arquivos:\n",
        "fileForTrainingBad = 'badqueries.txt'\n",
        "fileForTrainingGood = 'goodqueries.txt'\n",
        "\n",
        "fileForValidationBad = 'badqueries_gg.txt'\n",
        "fileForValidationGood = 'goodqueries_gg.txt'\n",
        "\n",
        "# Sufixo para escrita do nome do arquivo\n",
        "saveSuffix = '-lsvm-word'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhe7KjuaHpJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carregamos as bibliotecas.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkgz1ipxIF8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib.parse\n",
        "\n",
        "# Função que lê os dados do arquivo.\n",
        "def loadFile(name):\n",
        "    # Obtém diretório e nome completo do arquivo (com path).\n",
        "    directory = str(os.getcwd())\n",
        "    filepath = os.path.join(directory, name)\n",
        "\n",
        "    # Faz a leitura das linhas do arquivo.\n",
        "    with open(filepath,'r') as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    # Transforma as linhas em um Set (retira as duplicadas) e depois em uma lista.\n",
        "    data = list(set(data))\n",
        "\n",
        "    # Realiza o decode das URLs e coloca elas na lista result.\n",
        "    result = []\n",
        "    for d in data:\n",
        "        d = str(urllib.parse.unquote(d))\n",
        "        result.append(d)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRIZr0Zf4YhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "# Função que separa cada URL em uma lista de palavras/tokens, utilizando como separadores: '/', '-', '.'\n",
        "def getTokens(input):\n",
        "    return re.split(tokensSep, str(input.encode('utf-8')))\n",
        "\n",
        "# Exemplo:\n",
        "# getTokens('/wikipedia/noticias/museu-nacional-e-10.php?paramenter=10&c=select * from table&opa=<xss(alert)>')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zca_MRlOM_mL",
        "colab_type": "text"
      },
      "source": [
        "Vamos fazer a leitura dos dados do Google Drive (estamos executando no Google Colab para validação)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkVTQuSqIIuT",
        "colab_type": "code",
        "outputId": "3863cf3b-8281-42bc-aa40-04217b31ad0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH8iRtEAIyEH",
        "colab_type": "code",
        "outputId": "f0a9c5b9-c7eb-4f6e-eeaf-98d574b7c379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd drive/'My Drive'/'Colab Notebooks'/cpc802"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/Colab Notebooks/cpc802'\n",
            "/content/drive/My Drive/Colab Notebooks/cpc802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPmTkgPYKKVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criamos uma instância de dicionário para converter as URLs em representações\n",
        "#   numéricas de acordo com a frequência de utilização deles.\n",
        "if use_words:\n",
        "    vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"word\", sublinear_tf=True, tokenizer=getTokens)\n",
        "else:\n",
        "    vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SECyzjx_RaYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carrega os dados dos arquivos\n",
        "badQueries = loadFile(fileForTrainingBad)\n",
        "validQueries = loadFile(fileForTrainingGood)\n",
        "\n",
        "allQueries = badQueries + validQueries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zen-bT8QI9hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Geramos o vetor de conversão para as URLs.\n",
        "X = vectorizer.fit_transform(allQueries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcqGSyZiSyyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vamos colocar os labels\n",
        "#   0 - normal\n",
        "#   1 - malicious\n",
        "yBad = [1 for i in range(0, len(badQueries))]\n",
        "yGood = [0 for i in range(0, len(validQueries))]\n",
        "\n",
        "y = yBad + yGood\n",
        "\n",
        "# Vamos gerar os dados de treinamento e validação\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOYOiS_4KOLr",
        "colab_type": "code",
        "outputId": "33a509fa-d6b4-4254-959c-6cd3671badb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "badCount = len(badQueries)\n",
        "badCount"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44713"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeVHojw0TF7b",
        "colab_type": "code",
        "outputId": "f6994472-d6bc-494c-d68b-ac3e6484fc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validCount = len(validQueries)\n",
        "validCount"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1265994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZq2eEmhKcda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criamos um classificador usando o método indicado na configuração.\n",
        "if method == 'logreg':\n",
        "    model = LogisticRegression(class_weight='balanced', max_iter=400)\n",
        "if method == 'lsvm':\n",
        "    model = LinearSVC(C=10, max_iter=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRhs2HHnKspF",
        "colab_type": "code",
        "outputId": "d9187e45-6366-43e8-a7c8-23cdf6812a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Treinando o modelo.\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=400,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUdkpQ_cDaEr",
        "colab_type": "code",
        "outputId": "f14f7902-f6fe-46ad-e97a-07cf306372a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Salva modelo treinado no Google Drive.\n",
        "import joblib\n",
        "import time\n",
        "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "filename = 'cpc802-' + timestr + saveSuffix + '.sav'\n",
        "filenameVectorizer = 'cpc802-' + timestr + saveSuffix +'.vectorizer'\n",
        "joblib.dump(model, filename)\n",
        "joblib.dump(vectorizer, filenameVectorizer)"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cpc802-20200229-235821-lsvm-word.vectorizer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV2zv2yDKd5K",
        "colab_type": "code",
        "outputId": "ca177640-93cf-43f6-c639-2e94f30cb1bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Validamos o modelo\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "print(\"Bad samples: %d\" % badCount)\n",
        "print(\"Good samples: %d\" % validCount)\n",
        "print(\"Baseline Constant negative: %.6f\" % (validCount / (validCount + badCount)))\n",
        "print(\"Accuracy: %f\" % model.score(X_test, y_test))\n",
        "print(\"Precision: %f\" % metrics.precision_score(y_test, predicted))\n",
        "print(\"Recall: %f\" % metrics.recall_score(y_test, predicted))\n",
        "print(\"F1-Score: %f\" % metrics.f1_score(y_test, predicted))\n",
        "\n",
        "# Imprime apenas na regressão logística.\n",
        "if method == 'logreg':\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_test, (model.predict_proba(X_test)[:, 1]))\n",
        "    auc = metrics.auc(fpr, tpr)\n",
        "    print(\"AUC: %f\" % auc)"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bad samples: 44713\n",
            "Good samples: 1265994\n",
            "Baseline Constant negative: 0.965886\n",
            "Accuracy: 0.998054\n",
            "Precision: 0.992536\n",
            "Recall: 0.949343\n",
            "F1-Score: 0.970459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UEe_ApDWOft",
        "colab_type": "code",
        "outputId": "b34c717f-563f-455c-a480-73bb12a2fd4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Testando com valores conhecidos.\n",
        "X_predict = [\n",
        "             '/busca/manoel',\n",
        "             '/search=faizanahad',\n",
        "             '/getpassword.php',\n",
        "             '/wp-admin/includes/log.exe',\n",
        "             '/nethost.exe',\n",
        "             '/centroesteticosothys/img/_notes/gum.exe?c=select * from table',\n",
        "             '/node/add',\n",
        "             ]\n",
        "X_predict = vectorizer.transform(X_predict)\n",
        "\n",
        "# Imprime probabilidade apenas na regressão logística.\n",
        "if method == 'logreg':\n",
        "    y_Predict = model.predict_log_proba(X_predict)\n",
        "    print(y_Predict)\n",
        "\n",
        "y_Predict = model.predict(X_predict)\n",
        "print(y_Predict)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMAtm9DnVkxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepara dataset real apenas para validação.\n",
        "otherBadQueries = loadFile(fileForValidationBad)\n",
        "otherGoodQueries = loadFile(fileForValidationGood)\n",
        "allOtherQueries = otherBadQueries + otherGoodQueries\n",
        "\n",
        "# Vetoriza dataset real.\n",
        "X_real = vectorizer.transform(allOtherQueries)\n",
        "\n",
        "# Calcula as inferências do dataset real.\n",
        "y_real = model.predict(X_real)\n",
        "\n",
        "# Vamos colocar os labels no dataset real.\n",
        "#   0 - normal\n",
        "#   1 - malicious\n",
        "yBad_gg = [1 for i in range(0, len(otherBadQueries))]\n",
        "yGood_gg = [0 for i in range(0, len(otherGoodQueries))]\n",
        "y_real_with_label = yBad_gg + yGood_gg\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieX3JkRFYThu",
        "colab_type": "code",
        "outputId": "4ee08394-40aa-4c95-8248-f4d07e8aab32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Verifica acertos e erros de predição usando dataset real.\n",
        "acertos = 0\n",
        "erros = 0\n",
        "for i in range(len(y_real)):\n",
        "    if y_real[i] == y_real_with_label[i]:\n",
        "        acertos = acertos + 1\n",
        "    elif (y_real_with_label[i] == 0 and y_real[i] == 1):\n",
        "        acertos = acertos + 1\n",
        "    else:\n",
        "        erros = erros + 1\n",
        "\n",
        "acertos/len(y_real)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8092813606335998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY4Q74d-bT2x",
        "colab_type": "code",
        "outputId": "9d1b8c16-38e3-4ab9-84c7-4c69aa718528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Verifica acertos e erros de predição usando dataset de treino (é para verificar a acurácia).\n",
        "#   Nessa verificação levamos em conta os erros que não prejudicam a avaliação do domínio\n",
        "#   do problema, ou seja, quando o classificador aponta que uma URL é maliciosa e ela\n",
        "#   não é.\n",
        "\n",
        "# Vetoriza dataset usado no treinamento.\n",
        "X_trained = vectorizer.transform(allQueries)\n",
        "\n",
        "# Calcula as inferências do dataset real.\n",
        "y_trained = model.predict(X_trained)\n",
        "\n",
        "acertos = 0\n",
        "erros = 0\n",
        "for i in range(len(y_trained)):\n",
        "    if y_trained[i] == y[i]:\n",
        "        acertos = acertos + 1\n",
        "    elif (y[i] == 0 and y_trained[i] == 1):\n",
        "        acertos = acertos + 1\n",
        "    else:\n",
        "        erros = erros + 1\n",
        "\n",
        "acertos/len(y_trained)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9995971639733365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    }
  ]
}